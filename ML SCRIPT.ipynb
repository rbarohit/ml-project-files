{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(['Credit reporting, credit repair services, or other personal consumer reports'],'Credit reporting')\n",
    "df = df.replace(['Credit card or prepaid card'],'Credit card')\n",
    "df = df.replace(['Checking or savings account'],'Checking account')\n",
    "df = df.replace(['Money transfer, virtual currency, or money service'],'Money service')\n",
    "df = df.replace(['Vehicle loan or lease'],'Vehicle loan')\n",
    "df = df.replace(['Bank account or service'],'Bank account')\n",
    "df = df.replace(['Payday loan, title loan, or personal loan'],'Personal loan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = 'Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Credit reporting    364\n",
       "Debt collection     160\n",
       "Mortgage            100\n",
       "Credit card          76\n",
       "Checking account     36\n",
       "Student loan         35\n",
       "Money service        21\n",
       "Bank account         15\n",
       "Vehicle loan         14\n",
       "Personal loan         9\n",
       "Consumer Loan         7\n",
       "Prepaid card          3\n",
       "Payday loan           2\n",
       "Money transfers       2\n",
       "Name: tags, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tags = ['Credit reporting','Debt collection','Mortgage','Credit card','Checking account','Student loan','Money service','Bank account','Vehicle loan','Personal loan','Consumer Loan','Prepaid card','Payday loan','Money transfers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXX XXXX provided validation of debt with inaccuracies. The card acceptance certificate dated on XX/XX/XXXX to XXXX XXXX XXXX XXXX, TX XXXX was not my current address. From XX/XX/XXXX - XX/XX/XXXX, my home address was XXXX XXXX XXXX, TX XXXX and from XX/XX/XXXX to current my home address is XXXX XXXX XXXX XXXX, TX XXXX. My email address XXXX XXXX has listed for me is XXXX. This is also invalid. \n",
      "\n",
      "I will be filling a copy of the acceptance certificate with my police report.\n",
      "Tag: Credit reporting\n"
     ]
    }
   ],
   "source": [
    "def print_plot(index):\n",
    "    example = df[['post', 'tags']].values[0]\n",
    "    if len(example) > 0:\n",
    "        print(example[0])\n",
    "        print('Tag:', example[1])\n",
    "print_plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxxx xxxx provided validation debt inaccuracies card acceptance certificate dated xx xx xxxx xxxx xxxx xxxx xxxx tx xxxx current address xx xx xxxx xx xx xxxx home address xxxx xxxx xxxx tx xxxx xx xx xxxx current home address xxxx xxxx xxxx xxxx tx xxxx email address xxxx xxxx listed xxxx also invalid filling copy acceptance certificate police report\n",
      "Tag: Credit reporting\n"
     ]
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "    \n",
    "df['post'] = df['post'].apply(clean_text)\n",
    "print_plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df.post\n",
    "y_val = df.tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "flename_LOGREG = 'logreg.sav'\n",
    "filename_SDG = 'SDG.sav'\n",
    "flename_LOGREG2 = 'logreg_tuned.sav'\n",
    "filename_SDG2 = 'SDG_tuned.sav'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8957345971563981\n"
     ]
    }
   ],
   "source": [
    "loaded_model_LOGREG = pickle.load(open(flename_LOGREG2, 'rb'))\n",
    "result_LOGREG = loaded_model_LOGREG.score(X_val,y_val)\n",
    "print(result_LOGREG)\n",
    "y_pred_LOGREG = loaded_model_LOGREG.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result_LOGREG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.745260663507109\n"
     ]
    }
   ],
   "source": [
    "loaded_model_SDG = pickle.load(open(filename_SDG2, 'rb'))\n",
    "result_SDG = loaded_model_SDG.score(X_val,y_val)\n",
    "print(result_SDG)\n",
    "\n",
    "y_pred_SDG = loaded_model_SDG.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGREG SCORES HIGHER\n"
     ]
    }
   ],
   "source": [
    "if 'result_LOGREG' < 'result_SDG':\n",
    "    df['Predicted Class'] = y_pred_LOGREG\n",
    "    df.to_csv('LOGREG_Results.csv')\n",
    "    print('LOGREG SCORES HIGHER')\n",
    "else:\n",
    "    df['Predicted Class'] = y_pred_SDG\n",
    "    df.to_csv('SDG_Results.csv')\n",
    "    print('SDG SCORES HIGHER')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
